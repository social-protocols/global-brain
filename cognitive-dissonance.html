<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Cognitive Dissonance | Introduction to the Global Brain</title>
  <meta name="description" content="<p>This is a collection of explanations arount the Y platform. In this document,
we explain core concepts in simple terms that help to understand the
algorithms and components of the software.</p>" />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Cognitive Dissonance | Introduction to the Global Brain" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a collection of explanations arount the Y platform. In this document,
we explain core concepts in simple terms that help to understand the
algorithms and components of the software.</p>" />
  <meta name="github-repo" content="social-protocols/y-docs" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Cognitive Dissonance | Introduction to the Global Brain" />
  
  <meta name="twitter:description" content="<p>This is a collection of explanations arount the Y platform. In this document,
we explain core concepts in simple terms that help to understand the
algorithms and components of the software.</p>" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="rating-and-evaluating-content.html"/>
<link rel="next" href="information-value.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The Y Platform</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About</a></li>
<li class="chapter" data-level="2" data-path="global-brain-overview.html"><a href="global-brain-overview.html"><i class="fa fa-check"></i><b>2</b> Global Brain Overview</a>
<ul>
<li class="chapter" data-level="2.1" data-path="global-brain-overview.html"><a href="global-brain-overview.html#informed-votes"><i class="fa fa-check"></i><b>2.1</b> Informed Votes</a></li>
<li class="chapter" data-level="2.2" data-path="global-brain-overview.html"><a href="global-brain-overview.html#the-causal-model"><i class="fa fa-check"></i><b>2.2</b> The Causal Model</a></li>
<li class="chapter" data-level="2.3" data-path="global-brain-overview.html"><a href="global-brain-overview.html#distributed-reasoning"><i class="fa fa-check"></i><b>2.3</b> Distributed Reasoning</a></li>
<li class="chapter" data-level="2.4" data-path="global-brain-overview.html"><a href="global-brain-overview.html#informal-argument-model"><i class="fa fa-check"></i><b>2.4</b> Informal Argument Model</a></li>
<li class="chapter" data-level="2.5" data-path="global-brain-overview.html"><a href="global-brain-overview.html#example"><i class="fa fa-check"></i><b>2.5</b> Example</a></li>
<li class="chapter" data-level="2.6" data-path="global-brain-overview.html"><a href="global-brain-overview.html#reason-and-argument"><i class="fa fa-check"></i><b>2.6</b> Reason and Argument</a></li>
<li class="chapter" data-level="2.7" data-path="global-brain-overview.html"><a href="global-brain-overview.html#checking-misinformation"><i class="fa fa-check"></i><b>2.7</b> Checking Misinformation</a></li>
<li class="chapter" data-level="2.8" data-path="global-brain-overview.html"><a href="global-brain-overview.html#marketplace-of-ideas"><i class="fa fa-check"></i><b>2.8</b> Marketplace of Ideas</a></li>
<li class="chapter" data-level="2.9" data-path="global-brain-overview.html"><a href="global-brain-overview.html#defining-cognitive-dissonance"><i class="fa fa-check"></i><b>2.9</b> Defining Cognitive Dissonance</a></li>
<li class="chapter" data-level="2.10" data-path="global-brain-overview.html"><a href="global-brain-overview.html#cognitive-dissonance-as-relative-entropy"><i class="fa fa-check"></i><b>2.10</b> Cognitive Dissonance as Relative Entropy</a></li>
<li class="chapter" data-level="2.11" data-path="global-brain-overview.html"><a href="global-brain-overview.html#the-causal-model-1"><i class="fa fa-check"></i><b>2.11</b> The Causal Model</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="rating-and-evaluating-content.html"><a href="rating-and-evaluating-content.html"><i class="fa fa-check"></i><b>3</b> Rating and Evaluating Content</a>
<ul>
<li class="chapter" data-level="3.1" data-path="rating-and-evaluating-content.html"><a href="rating-and-evaluating-content.html#modeling-upvote-rates"><i class="fa fa-check"></i><b>3.1</b> Modeling Upvote Rates</a></li>
<li class="chapter" data-level="3.2" data-path="rating-and-evaluating-content.html"><a href="rating-and-evaluating-content.html#modeling-belief-about-the-true-upvote-rate"><i class="fa fa-check"></i><b>3.2</b> Modeling Belief about the ‚ÄúTrue‚Äù Upvote Rate</a></li>
<li class="chapter" data-level="3.3" data-path="rating-and-evaluating-content.html"><a href="rating-and-evaluating-content.html#estimating-the-true-upvote-rate"><i class="fa fa-check"></i><b>3.3</b> Estimating the True Upvote Rate</a></li>
<li class="chapter" data-level="3.4" data-path="rating-and-evaluating-content.html"><a href="rating-and-evaluating-content.html#the-bayesian-average"><i class="fa fa-check"></i><b>3.4</b> The Bayesian Average</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="cognitive-dissonance.html"><a href="cognitive-dissonance.html"><i class="fa fa-check"></i><b>4</b> Cognitive Dissonance</a>
<ul>
<li class="chapter" data-level="4.1" data-path="cognitive-dissonance.html"><a href="cognitive-dissonance.html#key-concepts-from-information-theory"><i class="fa fa-check"></i><b>4.1</b> Key Concepts from Information Theory</a></li>
<li class="chapter" data-level="4.2" data-path="cognitive-dissonance.html"><a href="cognitive-dissonance.html#surprisal-as-a-measure-of-error"><i class="fa fa-check"></i><b>4.2</b> Surprisal as a Measure of Error</a></li>
<li class="chapter" data-level="4.3" data-path="cognitive-dissonance.html"><a href="cognitive-dissonance.html#total-cross-entropy"><i class="fa fa-check"></i><b>4.3</b> Total Cross Entropy</a></li>
<li class="chapter" data-level="4.4" data-path="cognitive-dissonance.html"><a href="cognitive-dissonance.html#total-relative-entropy-cognitive-dissonance"><i class="fa fa-check"></i><b>4.4</b> Total Relative Entropy = Cognitive Dissonance</a></li>
<li class="chapter" data-level="4.5" data-path="cognitive-dissonance.html"><a href="cognitive-dissonance.html#detailed-example"><i class="fa fa-check"></i><b>4.5</b> Detailed Example</a></li>
<li class="chapter" data-level="4.6" data-path="cognitive-dissonance.html"><a href="cognitive-dissonance.html#discussion"><i class="fa fa-check"></i><b>4.6</b> Discussion</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="cognitive-dissonance.html"><a href="cognitive-dissonance.html#parallel-to-machine-learning"><i class="fa fa-check"></i><b>4.6.1</b> Parallel to Machine Learning</a></li>
<li class="chapter" data-level="4.6.2" data-path="cognitive-dissonance.html"><a href="cognitive-dissonance.html#a-subtle-point"><i class="fa fa-check"></i><b>4.6.2</b> A Subtle Point</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="information-value.html"><a href="information-value.html"><i class="fa fa-check"></i><b>5</b> Information Value</a>
<ul>
<li class="chapter" data-level="5.1" data-path="information-value.html"><a href="information-value.html#the-information-value-of-a-vote"><i class="fa fa-check"></i><b>5.1</b> The Information Value of a Vote</a></li>
<li class="chapter" data-level="5.2" data-path="information-value.html"><a href="information-value.html#information-value-of-changed-votes"><i class="fa fa-check"></i><b>5.2</b> Information Value of Changed Votes</a></li>
<li class="chapter" data-level="5.3" data-path="information-value.html"><a href="information-value.html#information-value-of-new-votes"><i class="fa fa-check"></i><b>5.3</b> Information Value of New Votes</a></li>
<li class="chapter" data-level="5.4" data-path="information-value.html"><a href="information-value.html#what-does-a-vote-mean"><i class="fa fa-check"></i><b>5.4</b> What Does a Vote Mean?</a></li>
<li class="chapter" data-level="5.5" data-path="information-value.html"><a href="information-value.html#example-1-a-storm-in-madrid"><i class="fa fa-check"></i><b>5.5</b> Example 1: A Storm in Madrid</a></li>
<li class="chapter" data-level="5.6" data-path="information-value.html"><a href="information-value.html#example-2-a-typhoon-in-oslo"><i class="fa fa-check"></i><b>5.6</b> Example 2: A Typhoon in Oslo</a></li>
<li class="chapter" data-level="5.7" data-path="information-value.html"><a href="information-value.html#desired-properties-of-information-value-formula"><i class="fa fa-check"></i><b>5.7</b> Desired Properties of Information Value Formula</a></li>
<li class="chapter" data-level="5.8" data-path="information-value.html"><a href="information-value.html#upvote-only-relative-entropy"><i class="fa fa-check"></i><b>5.8</b> Upvote-Only Relative Entropy</a></li>
<li class="chapter" data-level="5.9" data-path="information-value.html"><a href="information-value.html#example-charts"><i class="fa fa-check"></i><b>5.9</b> Example Charts</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to the Global Brain</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="cognitive-dissonance" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Chapter 4</span> Cognitive Dissonance<a href="cognitive-dissonance.html#cognitive-dissonance" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>As described in the <a href="global-brain-overview.html">Global Brain Overview</a>, the goal of the global brain algorithm is to focus users‚Äô attention on posts that reduce <strong>cognitive dissonance</strong> ‚Äì difference of belief that exist only exist because people have been exposed to different information. When a note on a post changes the probability that users upvote the post, then there is cognitive dissonance in proportion to the number of people who voted on the post without being shown the note. Information theory lets us easily quantify this cognitive dissonance using the concept of entropy.</p>
<div id="key-concepts-from-information-theory" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Key Concepts from Information Theory<a href="cognitive-dissonance.html#key-concepts-from-information-theory" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here‚Äôs a quick summary of the relevant concepts of information theory:</p>
<ul>
<li><strong>surprisal</strong>: how surprised I am when I learn that the value of X is x:</li>
</ul>
<p><span class="math display">\[Suprisal(x) = -{\lg P(X=x)}\]</span></p>
<ul>
<li><strong>entropy</strong>: how surprised I expect to be:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
    H(P) &amp;= ùîº Suprisal(X) \\
         &amp;= ùîº -{\lg P(X)}  \\
         &amp;= ‚àë_x P(X=x) √ó -{\lg P(X=x)} \\
\end{aligned}
\]</span></p>
<ul>
<li><strong>cross-entropy</strong>: how surprised I expect Bob to be (if Bob‚Äôs beliefs are <span class="math inline">\(Q\)</span> instead of <span class="math inline">\(P\)</span>):</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
    H(P,Q) &amp;= ùîº Suprisal_Q(X) \\
           &amp;= ùîº -{\lg Q(X)} \\
           &amp;= ‚àë_x P(X=x) √ó -{\lg Q(X=x)}
\end{aligned}
\]</span></p>
<ul>
<li><strong>relative entropy</strong> or <strong>KL divergence</strong>: how much <em>more</em> surprised I expect Bob to be than me:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
        D_{KL}(P || Q) &amp;= H(P,Q) - H(P) \\
                    &amp;= ‚àë_x P(X=x) √ó {\lg \frac{P(X=x)}{Q(X=x)}}
\end{aligned}
\]</span></p>
<p>When dealing with binary variables then these formulas can be written as:</p>
<ul>
<li><strong>entropy</strong>:</li>
</ul>
<p><span class="math display">\[ H(p) = - p √ó {\lg p} - (1-p) √ó {\lg (1-p)} \]</span></p>
<ul>
<li><strong>cross-entropy</strong>:</li>
</ul>
<p><span class="math display">\[ H(p,q) = - p √ó -{\lg q} - (1-p) √ó {\lg (1-q)} \]</span></p>
<ul>
<li><strong>relative entropy or KL-divergence</strong>:</li>
</ul>
<p><span class="math display">\[ D_{KL}(p||q) = - p √ó {\lg \frac{p}{q}} - (1-p) √ó {\lg \frac{1-p}{1-q}} \]</span></p>
</div>
<div id="surprisal-as-a-measure-of-error" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Surprisal as a Measure of Error<a href="cognitive-dissonance.html#surprisal-as-a-measure-of-error" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Surprisal can be thought of, for our purposes, as a measure of the ‚Äúerror‚Äù of a prediction. If we predict that something has a 1% chance of happening, and it happens, surprisal is <span class="math inline">\(-{\lg .01} = 6.64~bits\)</span>, whereas if we predicted it had a 99% chance of happening, surprisal is only <span class="math inline">\(-{\lg .99} = 0.14~bits\)</span>, which is much smaller. If we thought there was a 50/50 chance, surprisal is <span class="math inline">\(-{\lg .5} = 1~bit\)</span>.</p>
<p>Suppose we predict that the probability of a user upvoting a post is <span class="math inline">\(p\)</span>. Then suppose there are actually <span class="math inline">\(upvotes\)</span> upvotes and <span class="math inline">\(downvotes\)</span> downvotes. What is the total error of our predictions?</p>
<p>Every time there is an upvote, surprisal is <span class="math inline">\(-{\lg p}\)</span>. The probability of a downvote is just <span class="math inline">\(1-p\)</span>, so whenever there is a downvote surprisal is <span class="math inline">\(-{\lg (1-p)}\)</span>.</p>
<p>So our total error is:</p>
<p><span class="math display">\[
    upvotes √ó -{\lg p} + downvotes √ó -{\lg (1-p)}
\]</span></p>
<p>Since <span class="math inline">\(upvotes ‚âà votesTotal√óp\)</span>, and <span class="math inline">\(downvotes ‚âà votesTotal√ó(1-p)\)</span> our total error is approximately:</p>
<p><span class="math display">\[
\begin{aligned}
    &amp; votesTotal √ó p √ó -{\lg p} + votesTotal √ó (1-p) √ó -{\lg (1-p)} \\
    &amp; = votesTotal √ó H(p)
\end{aligned}
\]</span></p>
<p>In other words, our error is roughly entropy times the number of votes.</p>
</div>
<div id="total-cross-entropy" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Total Cross Entropy<a href="cognitive-dissonance.html#total-cross-entropy" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let‚Äôs say Alice estimates the probability of an upvote to be <span class="math inline">\(q\)</span>, but Bob thinks the probability of an upvote is <span class="math inline">\(p\)</span>. So Bob‚Äôs measure of Alice‚Äôs error will different from Alice‚Äôs measure of her own error! Bob‚Äôs measure of Alice‚Äôs error is:</p>
<p><span class="math display">\[
\begin{aligned}
    &amp;upvotes √ó -{\lg q} + downvotes √ó -{\lg (1-q)} \\
    &amp;‚âà votesTotal√óp √ó -{\lg q} + votesTotal√ó(1-p) √ó -{\lg (1-q)} )  \\
    &amp;= votesTotal√ó( p√ó-{\lg q} + (1-p)√ó-{\lg (1-q)} ) \\
    &amp;= votesTotal√óH(p,q) \\
\end{aligned}
\]</span></p>
<p><span class="math inline">\(H(p,q)\)</span> is the cross entropy between Bob and Alices‚Äôs estimates: Bob‚Äôs estimate of Alice‚Äôs average error.</p>
<p>In our case, Alice represents the average uninformed user (users who haven‚Äôt seen the note on a post), and Bob represents the informed user. There are <span class="math inline">\(votesTotal\)</span> ‚ÄúAlices‚Äù, or uninformed users. Bob expects the total error of all the uninformed users to be <span class="math inline">\(votesTotal√óH(p,q)\)</span>.</p>
<p><span class="math inline">\(H(p,q)\)</span> will always be greater than <span class="math inline">\(H(p)\)</span> if <span class="math inline">\(p‚â†q\)</span>. That is, Bob‚Äôs measure of Alice‚Äôs error will always be greater than his measure of his own error as long as his beliefs differ from Alice‚Äôs.</p>
<p>This is due to a very powerful property of surprisal as a measure of error: expected surprisal is minimized when the estimated probability equals the actual frequency of the event. So over- or under- estimating the probability always results in more error in the long run. Since <span class="math inline">\(H(p,q)\)</span> tells us what Alice‚Äôs average error <em>would</em> be, in the long run, if <span class="math inline">\(p\)</span> were the true frequency, <span class="math inline">\(H(p,q)\)</span> is minimized when Alice‚Äôs estimate <span class="math inline">\(q\)</span> equals the true frequency <span class="math inline">\(p\)</span>, or when <span class="math inline">\(H(p,q)=H(p,p)=H(p)\)</span>.</p>
</div>
<div id="total-relative-entropy-cognitive-dissonance" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Total Relative Entropy = Cognitive Dissonance<a href="cognitive-dissonance.html#total-relative-entropy-cognitive-dissonance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The difference between <span class="math inline">\(H(p,q)\)</span> and <span class="math inline">\(H(p)\)</span> is <strong>relative entropy</strong>, also known as the Kullback‚ÄìLeibler divergence or KL-divergence. It can be thought of as ‚Äúhow much <strong>more</strong> surprised Bob expects Alice to be than himself‚Äù. Since <span class="math inline">\(H(p,q) &gt;= H(p)\)</span>, <strong>relative entropy is never negative</strong>, regardless of whether <span class="math inline">\(p\)</span> is greater or less than <span class="math inline">\(q\)</span>.</p>
<p>If we take Bob‚Äôs measure of Alices‚Äôs total error, minus his measure of his own total error, we get the total relative entropy: how much <strong>more</strong> error Bob expects for Alice than he would expect if Alice knew more.</p>
<p>The total relative entropy is our measure of cognitive dissonance.</p>
<p><span class="math display">\[
\begin{aligned}
cognitiveDissonance  &amp;= votesTotal √ó H(p,q) - votesTotal √ó H(p) \\
            &amp;= votesTotal √ó ( H(p,q) - H(p) ) \\
            &amp;= votesTotal √ó D_{KL}(p || q)
\end{aligned}
\]</span></p>
</div>
<div id="detailed-example" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Detailed Example<a href="cognitive-dissonance.html#detailed-example" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose a post without a note is given receives 900 upvotes and 100 downvotes. But a certain note, when shown along with the post, reduces the upvote probability to 20%.</p>
<p>The total cognitive dissonance is</p>
<p><span class="math display">\[
\begin{aligned}
        cognitiveDissonance    &amp;= votesTotal √ó D_{KL}(p || q) \\
                               &amp;= votesTotal √ó ( p √ó {\lg \frac{p}{q}} + (1-p) √ó {\lg \frac{1-p}{1-q}} ) \\
                               &amp;= 1000 √ó ( .2 √ó lg~\frac{.2}{.9} + .8 √ó lg~\frac{.8}{.1} )  \\
                               &amp;= 1966.01~bits
\end{aligned}
\]</span></p>
<p>Suppose that, after showing the note to users that already upvoted the post, 70 users change their upvote to a downvote.</p>
<p>The new upvote probability <span class="math inline">\(q_1\)</span> will be approximately</p>
<p><span class="math display">\[
\begin{aligned}
    q_1  &amp;‚âà \frac{upvotes - 70}{votesTotal} \\
       &amp;= \frac{900 - 70}{1000} \\
       &amp;= .83
\end{aligned}
\]</span></p>
<p>The new cognitive dissonance will therefore be</p>
<p><span class="math display">\[
\begin{aligned}
    cognitiveDissonance_1 \\
    &amp;= votesTotal √ó DKL(p, q_1)\\
    &amp;= votesTotal √ó DKL(.2, .83 ) \\
    &amp;= 1376.95~bits
\end{aligned}
\]</span></p>
<p>So cognitive dissonance was decreased by <span class="math inline">\(1966.01-1376.95 ‚âà 589\)</span> bits. Or in other words, 589 of information was gained.</p>
<p>The table below shows how relative cognitive dissonance falls as users change upvotes to downvotes, reaching zero when <span class="math inline">\(p=q_t\)</span> and therefore <span class="math inline">\(upvotes=p√óvotesTotal=200\)</span>.</p>
<table>
<thead>
<tr class="header">
<th align="right">q_t</th>
<th align="right">upvotes</th>
<th align="right">dkl</th>
<th align="right">dissonance</th>
<th align="right">informationValue</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.90</td>
<td align="right">900</td>
<td align="right">1.9660150</td>
<td align="right">1966.01500</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="right">0.83</td>
<td align="right">830</td>
<td align="right">1.3769499</td>
<td align="right">1376.94994</td>
<td align="right">589.06506</td>
</tr>
<tr class="odd">
<td align="right">0.76</td>
<td align="right">760</td>
<td align="right">1.0043726</td>
<td align="right">1004.37259</td>
<td align="right">372.57734</td>
</tr>
<tr class="even">
<td align="right">0.69</td>
<td align="right">690</td>
<td align="right">0.7368662</td>
<td align="right">736.86616</td>
<td align="right">267.50644</td>
</tr>
<tr class="odd">
<td align="right">0.62</td>
<td align="right">620</td>
<td align="right">0.5327468</td>
<td align="right">532.74682</td>
<td align="right">204.11933</td>
</tr>
<tr class="even">
<td align="right">0.55</td>
<td align="right">550</td>
<td align="right">0.3721737</td>
<td align="right">372.17368</td>
<td align="right">160.57315</td>
</tr>
<tr class="odd">
<td align="right">0.48</td>
<td align="right">480</td>
<td align="right">0.2445838</td>
<td align="right">244.58382</td>
<td align="right">127.58985</td>
</tr>
<tr class="even">
<td align="right">0.41</td>
<td align="right">410</td>
<td align="right">0.1443033</td>
<td align="right">144.30325</td>
<td align="right">100.28057</td>
</tr>
<tr class="odd">
<td align="right">0.34</td>
<td align="right">340</td>
<td align="right">0.0689202</td>
<td align="right">68.92023</td>
<td align="right">75.38302</td>
</tr>
<tr class="even">
<td align="right">0.27</td>
<td align="right">270</td>
<td align="right">0.0190909</td>
<td align="right">19.09095</td>
<td align="right">49.82928</td>
</tr>
<tr class="odd">
<td align="right">0.20</td>
<td align="right">200</td>
<td align="right">0.0000000</td>
<td align="right">0.00000</td>
<td align="right">19.09095</td>
</tr>
</tbody>
</table>
<p><img src="_main_files/figure-html/unnamed-chunk-17-1.png" width="576" /></p>
<p>Note how the rate of reduction of cognitive dissonance falls as <span class="math inline">\(q\)</span> approaches <span class="math inline">\(p\)</span>.</p>
<p>Focusing attention on posts and notes that maximize the rate of reduction of cognitive dissonance is the overall goal of the global brain algorithm. See the next document on [information-value.html].</p>
</div>
<div id="discussion" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> Discussion<a href="cognitive-dissonance.html#discussion" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="parallel-to-machine-learning" class="section level3 hasAnchor" number="4.6.1">
<h3><span class="header-section-number">4.6.1</span> Parallel to Machine Learning<a href="cognitive-dissonance.html#parallel-to-machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Cross entropy is commonly used used as the cost function in many machine learning algorithms. A neural network for example takes an input with labels (e.g.¬†images of cats and dogs) and outputs an estimated probability (e.g.¬†that the image is a cat). The cost function computes how far these probability estimates are from the correct labels, and the neural network is trained by minimizing the cost function.</p>
<p>If <span class="math inline">\(yÃÇ_i\)</span> is the machine‚Äôs predicted probability for training example <span class="math inline">\(i\)</span>, and <span class="math inline">\(y_i\)</span> is the correct output (1 or 0), then the total cross entropy cost is:</p>
<p><span class="math display">\[
    \sum_i H(y_i, yÃÇ) = \sum_i y_i √ó -{\lg yÃÇ_i} + (1-y_i) √ó -{\lg(1 - yÃÇ_i)}
\]</span></p>
<p>In our case, if we say that <span class="math inline">\(y_i\)</span> are users votes, and <span class="math inline">\(yÃÇ_i\)</span> is always equal to the uninformed users prediction <span class="math inline">\(q\)</span>, then our cost function is identical to the cost function used when training a neural network:</p>
<p><span class="math display">\[
\begin{aligned}
    \sum_i H(y_i, q) &amp;= \sum_i y_i √ó -{\lg yÃÇ_i} + (1-y_i) √ó -{\lg(1 - yÃÇ_i)} \\
                     &amp;= \sum_i y_i √ó -{\lg q} + (1-y_i) √ó -{\lg(1 - q)}  \\
                     &amp;= upvotes √ó -{\lg q} + downvotes  √ó -{\lg(1 - q)} \\
                     &amp;‚âà votesTotal√óH(p,q) \\
\end{aligned}
\]</span></p>
<p>So both neural networks and the global brain ‚Äúlearn‚Äù by reducing cross entropy. The difference is that the global brain reduces entropy not by learning to make better predictions, but by in a sense teaching users to make better predictions of how a fully-informed user would vote.</p>
</div>
<div id="a-subtle-point" class="section level3 hasAnchor" number="4.6.2">
<h3><span class="header-section-number">4.6.2</span> A Subtle Point<a href="cognitive-dissonance.html#a-subtle-point" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Note that cross-entropy in our case is a measure of the total surprise of uninformed users at the hypothetical future votes of informed users. That is to say, it is:</p>
<p><span class="math display">\[
\begin{aligned}
    &amp;votesTotal√óp √ó -{\lg q} \\
    &amp;+ votesTotal√ó(1-p) √ó -{\lg (1-q)} ) \\
    &amp;‚âà hypotheticalInformedUpvotes √ó -{\lg q} \\
    &amp;+ hypotheticalInformedDownvotes √ó -{\lg (1-q)} ) \\
    &amp;= votesTotal√óH(p,q)
\end{aligned}
\]</span></p>
<p>And not</p>
<p><span class="math display">\[
\begin{aligned}
    &amp; votesTotal√óq √ó -{\lg q} \\
    &amp;+ votesTotal√ó(1-q) √ó -{\lg (1-q)} ) \\
    &amp;‚âà actualUpvotes √ó -{\lg q} \\
    &amp;+ actualDownvotes √ó -{\lg (1-q)} ) \\
    &amp;= votesTotal√óH(q)
\end{aligned}
\]</span></p>
<p>This is potentially confusing (it caused me a great deal of confusion initially) because we are measuring the error of Alice‚Äôs estimated probability <span class="math inline">\(q\)</span> with respect to hypothetical events that have have not yet actually occurred. But shouldn‚Äôt we be measuring the error of the votes that have occurred?</p>
<p>No, because surprisal is a measure of the error of a probability estimate, no the error of the event. The events are ‚Äúwhat actually happens‚Äù or, in case of uncertainty, ‚Äúwhat we think will actually happen‚Äù given our best current estimate <span class="math inline">\(p\)</span>.</p>
<p>Measuring error against actual vote events just gives us <span class="math inline">\(votesTotal*H(q)\)</span>, which doesn‚Äôt tell us how much actual votes differ from what they should be if users were more informed.</p>
<p><span class="math inline">\(votesTotal√óH(p,q)\)</span> makes the most sense as a measure of the tension between the current state of user‚Äôs beliefs, and what that state <strong>should</strong> be, which is a hypothetical future where all users have changed their upvotes because of the information in the note, and thus <span class="math inline">\(actualUpvotes = hypotheticalInformedUpvotes\)</span> and <span class="math inline">\(actualDownvotes = hypotheticalInformedDownvotes\)</span>.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="rating-and-evaluating-content.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="information-value.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/2023-10-16-cognitive-dissonance.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
