# Modeling Upvote Probability {#modeling-upvote-probability}

<!-- We denote the event of a user adding either an upvote or a downvote to a post simply as a **vote**. -->
<!-- For any given post, we can represent the stream of incoming votes as a Poisson process. -->

<!-- $$ -->
<!-- \text{voteRate} \sim \text{Pois}(\lambda_V) -->
<!-- $$ -->

<!-- $\lambda_V$ is the rate parameter of the Poisson process. -->
<!-- We call this rate the **vote rate** of the post. -->
<!-- Posts with a high vote rate receive many votes per unit of time, posts with a low vote rate receive few. -->

<!-- We can represent the stream of incoming *upvotes* as a Poisson process as well: -->

<!-- $$ -->
<!-- \text{upvoteRate} \sim \text{Pois}(\lambda_U) -->
<!-- $$ -->

<!-- We call $\lambda_U$ the **upvote rate**. -->
<!-- The **downvote rate** is defined analogously, but we will mostly ignore it because it can be inferred from the upvote rate and the vote rate and is thus mostly redundant. -->

<!--- [TODO: graphics exemplifying vote rates] --->


Given a tally of votes at a certain point in time, we can calculate the **upvote ratio** at that time $t$ which is given by $upvotes:downvotes$.
We can also express it as the fraction of upvotes over all votes:

$$
\frac{upvotes}{upvotes + downvotes}
$$

You can think about the upvote fraction as an **average vote** or as the **probability of a vote being an upvote** (we will mostly call this the **upvote probability**).
We model votes as a Bernoulli distributed random variable with successes given by upvotes and failures given by downvotes.
If we encode upvotes with a value of $1$ and downvotes with a value of $0$, a sample post's gathered votes at a certain point in time $t$ might look like this:

$$
(1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0)
$$

The post has gathered a total of 12 votes of which 3 are upvotes and 9 are downvotes.
The upvote fraction or the average vote for this sample is:

$$
\text{upvoteFraction} = \frac{\sum_{i=1}^n x_i}{n} = \frac{upvotes}{upvotes + downvotes} = \frac{3}{3 + 9} = 0.25
$$


## The Beta-Bernoulli Model {#beta-bernoulli-model}

We assume that each post has a "true" upvote probability that we can only estimate by collecting votes.
Votes are modeled as a Bernoulli random variable with parameter $p$ that denotes our upvote probability.
Upvote probility is modeled as a Beta distribution.
The Beta distribution has two shape parameters $\alpha$ and $\beta$ which in our case are given by our upvote and downvote counts.

$$
u_i \sim \text{Bernoulli}(p) \\
p \sim \text{Beta}(upvotes, downvotes)
$$

### Example {-}

```{r, include=FALSE}
beta_data <- function(alpha, beta, samples) {
  data.frame(x = seq(0, 1, len = samples)) %>%
    mutate(y = dbeta(x, alpha, beta))
}

```

To provide a more intuitive understanding of how this distribution models our upvote probability, let's see how our beliefs about the true upvote probability develop for an example post when we collect more and more votes.
Let's say we have a post with a true upvote probability of $0.24$.
We initialize the distribution with a prior of 1 upvote and 1 downvote.
This is equivalent to a uniform distribution which means we assign equal weight to any upvote probability.

```{r, fig.width=8, fig.height=3}
beta_data(1, 1, 1000) %>%  
  data.frame() %>% 
  ggplot() +
  geom_line(aes(x = x, y = y), color = "black", linewidth = 1) +
  geom_vline(xintercept = 0.24, color = "red", linetype = "dashed") +
  scale_y_continuous(limits = c(0, 4)) +
  labs(
    title = "After 0 votes",
    x = "p",
    y = "Density",
    caption = "The red dashed line indicates the true upvote probability"
  ) +
  theme_sp()

```

Now, we observe some votes.

<!-- (1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0) -->
$$
(\color{limegreen}{1, 0, 0})
$$

```{r, fig.width=8, fig.height=3}
beta_data(2, 3, 1000) %>%  
  data.frame() %>% 
  ggplot() +
  geom_line(aes(x = x, y = y), color = "black", linewidth = 1) +
  geom_vline(xintercept = 0.24, color = "red", linetype = "dashed") +
  scale_y_continuous(limits = c(0, 4)) +
  labs(
    title = "After 3 votes: 1 up, 2 down",
    x = "p",
    y = "Density",
    caption = "The red dashed line indicates the true upvote probability"
  ) +
  theme_sp()

```

<!-- (1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0) -->
$$
(\color{grey}{1, 0, 0,} \color{limegreen}{0, 1, 0})
$$

```{r, fig.width=8, fig.height=3}
beta_data(3, 5, 1000) %>%  
  data.frame() %>% 
  ggplot() +
  geom_line(aes(x = x, y = y), color = "black", linewidth = 1) +
  geom_vline(xintercept = 0.24, color = "red", linetype = "dashed") +
  scale_y_continuous(limits = c(0, 4)) +
  labs(
    title = "After 6 votes: 2 up, 4 down",
    x = "p",
    y = "Density",
    caption = "The red dashed line indicates the true upvote probability"
  ) +
  theme_sp()

```

<!-- (1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0) -->
$$
(\color{grey}{1, 0, 0, 0, 1, 0,} \color{limegreen}{0, 0, 0})
$$

```{r, fig.width=8, fig.height=3}
beta_data(3, 8, 1000) %>%  
  data.frame() %>% 
  ggplot() +
  geom_line(aes(x = x, y = y), color = "black", linewidth = 1) +
  geom_vline(xintercept = 0.24, color = "red", linetype = "dashed") +
  scale_y_continuous(limits = c(0, 4)) +
  labs(
    title = "After 9 votes: 2 up, 7 down",
    x = "p",
    y = "Density",
    caption = "The red dashed line indicates the true upvote probability"
  ) +
  theme_sp()

```

<!-- (1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0) -->
$$
(\color{grey}{1, 0, 0, 0, 1, 0, 0, 0, 0,} \color{limegreen}{1, 0, 0})
$$

```{r, fig.width=8, fig.height=3}
beta_data(4, 10, 1000) %>%  
  data.frame() %>% 
  ggplot() +
  geom_line(aes(x = x, y = y), color = "black", linewidth = 1) +
  geom_vline(xintercept = 0.24, color = "red", linetype = "dashed") +
  scale_y_continuous(limits = c(0, 4)) +
  labs(
    title = "After 12 votes: 3 up, 9 down",
    x = "p",
    y = "Density",
    caption = "The red dashed line indicates the true upvote probability"
  ) +
  theme_sp()

```

As we update our beliefs, the probability mass becomes more concentrated which means we become more and more certain about our beliefs about the true upvote probability.
If the post would develop further with a similar trajectory, the following could be the outcome after 500 votes:

```{r, fig.width=8, fig.height=3}
beta_data(120, 380, 1000) %>%  
  data.frame() %>% 
  ggplot() +
  geom_line(aes(x = x, y = y), color = "black", linewidth = 1) +
  geom_vline(xintercept = 0.24, color = "red", linetype = "dashed") +
  labs(
    title = "After 500 votes: 120 up, 380 down",
    x = "p",
    y = "Density",
    caption = "The red dashed line indicates the true upvote probability"
  ) +
  theme_sp()

```

Our probability mass is now pretty concentrated around (what in this case we know to be) the true upvote probability.


## Naive Point Estimate

Now that we can express our beliefs about the upvote probability, how do we make a "best guess" at any given point in time?
A naive way of estimating the upvote probability is to take the actual current ratio $upvotes:downvotes$, or rather the fraction, which is equivalent to the **plain sample average vote**:

$$
P_t(upvote) = \frac{\sum_{i=1}^n x_i}{n} = \frac{upvotes}{upvotes + downvotes}
$$

This solution is naive because it ignores an important fact:
In the beginning, **we do not take into consideration any prior information about the upvote probability of the post**.
Thus, when the post does not yet have a lot of votes, each new arriving vote has an outsized effect on our estimate that only gets increasingly small over time.
This would result in **erratic estimates** in the beginning which would only smooth out over time.
Here is how the cumulative mean develops for a random vote history with a true upvote rate of $0.6$:

```{r, fig.width=8, fig.height=5}
set.seed(5)
n_votes <- 100
data <- data.frame(
  idx = seq(1, n_votes),
  x = rbinom(n_votes, size = 1, 0.6)
) %>% 
  mutate(cum_mean = cummean(x))

data %>% 
  ggplot(aes(x = idx, y = cum_mean)) +
  geom_line(color = "firebrick", linewidth = 1) +
  scale_y_continuous(limits = c(0, 1)) +
  geom_hline(yintercept = 0.6, color = "black", linetype = "dashed") +
  geom_text(x = 90, y = 0.65, label = "true upvote rate: 0.6") +
  labs(
    x = "After N votes",
    y = "Cumulative Mean"
  ) +
  theme_sp()

```

If we were to use this metric to compare posts, getting a high upvote probability estimate in the early stages of a post would essentially come down to luck.
It will temporarily fare overly well or overly poorly compared to other posts and the estimate will only get better over time once we have more votes on the post.
We have to take into account **prior information** to avoid this.


## The Bayesian Average

The Bayesian Average uses a **weighted prior estimate of the average** to avoid the
erratic shifts in the estimate when there is not a lot of data.
It is calculated as...

$$
\frac{\color{blue}{C \cdot m} + \sum_{i=1}^n x_i}{\color{blue}{C} + n}
$$

... where $C$ is a weight constant and $m$ is our prior belief about the average.
If you compare it to the plain average, <span style="color: blue">we simply add $C \cdot m$ to the nominator and $C$ to the denominator</span>.

**But what does this achieve in concrete terms?**

Let's build up to this formula step by step for estimating the
true upvote probability of a post.
First, remember that the sample upvote fraction can be thought of as the "plain" average vote.
In our case, this means:

- $\sum_{i=1}^n{x_i} = upvotes$ is the *number of upvotes*
- $n = upvotes + downvotes$ is the *total number of votes*

Substituting the values in the Bayesian average formula gives us:

$$
\frac{C \cdot m + \sum_{i=1}^n x_i}{C + n} = \frac{C \cdot m + upvotes}{C + upvotes + downvotes}
$$

**Adding these terms to our formula means that we calculate the
cumulative average as if we had collected $C$ votes with an upvote rate of $m$
before we collected the first vote on our post.**

If our prior belief about the average is $0.68$ and we chose a weighting factor of, say,
$100$, this would mean that we calculate the average as if we had previously
collected $100$ data points which amounted to an upvote fraction of exactly $0.68$.

Plugging in the values makes this apparent:

$$
\frac{100 \cdot 0.68 + upvotes}{100 + upvotes + downvotes} = \frac{68 + upvotes}{100 + upvotes + downvotes}
$$

Graphically, it looks like this (the light grey line is the plain average for
comparison):

```{r, fig.width=8, fig.height=5}
set.seed(12)
n_votes <- 100
votes <- rbinom(n_votes, size = 1, 0.6)
data_plain <- data.frame(
  idx = seq(1, n_votes),
  x = votes,
  is_prior = FALSE
) %>% 
  mutate(cum_mean_plain = cummean(x)) %>% 
  union(
    data.frame(
      idx = seq(-9, 0),
      x = NA,
      is_prior = TRUE,
      cum_mean_plain = NA
    )
  ) %>% 
  arrange(idx) %>% 
  select(-x)

data_bayes <- data.frame(
  idx = seq(1, n_votes),
  x = votes,
  is_prior = FALSE
) %>% 
  union(
    data.frame(
      idx = seq(-9, 0),
      x = 0.68,
      is_prior = TRUE
    )
  ) %>% 
  arrange(idx) %>% 
  mutate(cum_mean_bayes = cummean(x)) %>% 
  select(-x)

data_plain %>% 
  left_join(data_bayes, by = c("idx", "is_prior")) %>% 
  pivot_longer(
    cols = c(cum_mean_plain, cum_mean_bayes),
    names_to = "metric",
    values_to = "value",
    values_drop_na = TRUE
  ) %>% 
  ggplot(aes(x = idx, y = value)) +
  geom_line(aes(alpha = metric), linewidth = 1) +
  scale_y_continuous(limits = c(0, 1)) +
  scale_alpha_manual(
    values = c(
      "cum_mean_bayes" = 1.0,
      "cum_mean_plain" = 0.2
    ),
  ) +
  geom_text(x = 16, y = 0.95, label = "start of data collection") +
  geom_text(x = 90, y = 0.55, label = "true upvote rate", color = "red") +
  geom_text(x = -5, y = 0.72, label = "prior", color = "black") +
  geom_hline(yintercept = 0.6, color = "red", linetype = "dashed") +
  geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
  labs(
    x = "After N votes",
    y = "Cumulative Bayesian Average"
  ) +
  theme_sp() +
  theme(legend.position = "None")

```

The cumulative Bayesian average is much less erratic when little data is available.
However, there is an important question left:
How do we chose a good prior and a good weight?

Here is how the Bayesian average develops for different prior beliefs about the
average.
Bayesian averages over time are indicated by light grey lines, the priors chosen
here are $0.1$ through $0.9$ and the weight is kept constant at $20$.
The plain average is overlayed in darker grey for reference.

```{r, fig.width=8, fig.height=5}
C <- 20

data_plain <- data.frame(
  idx = seq(1, n_votes),
  x = votes
) %>% 
  mutate(cum_mean_plain = cummean(x))
  
data_bayes <-
  data_plain %>%
  mutate(
    bayesian_avg_10 = (C * 0.1 + cumsum(x)) / (C + idx),
    bayesian_avg_20 = (C * 0.2 + cumsum(x)) / (C + idx),
    bayesian_avg_30 = (C * 0.3 + cumsum(x)) / (C + idx),
    bayesian_avg_40 = (C * 0.4 + cumsum(x)) / (C + idx),
    bayesian_avg_50 = (C * 0.5 + cumsum(x)) / (C + idx),
    bayesian_avg_60 = (C * 0.6 + cumsum(x)) / (C + idx),
    bayesian_avg_70 = (C * 0.7 + cumsum(x)) / (C + idx),
    bayesian_avg_80 = (C * 0.8 + cumsum(x)) / (C + idx),
    bayesian_avg_90 = (C * 0.9 + cumsum(x)) / (C + idx),
  ) %>% 
  pivot_longer(
    cols = c(
      cum_mean_plain,
      bayesian_avg_10,
      bayesian_avg_20,
      bayesian_avg_30,
      bayesian_avg_40,
      bayesian_avg_50,
      bayesian_avg_60,
      bayesian_avg_70,
      bayesian_avg_80,
      bayesian_avg_90
    ),
    names_to = "metric",
    values_to = "value"
  ) %>% 
  mutate(is_bayesian_avg = stringr::str_starts(metric, "bayes"))

data_bayes %>% 
  ggplot(
    aes(
      x = idx,
      y = value,
      group = metric,
      color = metric
    )
  ) +
  geom_line(linewidth = 1) +
  scale_y_continuous(limits = c(0, 1)) +
  scale_color_manual(
    values = c(
      "bayesian_avg_10" = "grey80",
      "bayesian_avg_20" = "grey80",
      "bayesian_avg_30" = "grey80",
      "bayesian_avg_40" = "grey80",
      "bayesian_avg_50" = "grey80",
      "bayesian_avg_60" = "grey80",
      "bayesian_avg_70" = "grey80",
      "bayesian_avg_80" = "grey80",
      "bayesian_avg_90" = "grey80",
      "cum_mean" = "black"
    )
  ) +
  geom_hline(yintercept = 0.6, color = "red", linetype = "dashed") +
  geom_text(x = 90, y = 0.57, label = "true upvote rate = 0.6", color = "red") +
  theme_sp() +
  theme(legend.position = "None")

```

And here is that same plot with the same priors, but with a weight of $100$.

```{r, fig.width=8, fig.height=5}
C <- 100

data_plain <- data.frame(
  idx = seq(1, n_votes),
  x = votes
) %>% 
  mutate(cum_mean_plain = cummean(x))
  
data_bayes <-
  data_plain %>%
  mutate(
    bayesian_avg_10 = (C * 0.1 + cumsum(x)) / (C + idx),
    bayesian_avg_20 = (C * 0.2 + cumsum(x)) / (C + idx),
    bayesian_avg_30 = (C * 0.3 + cumsum(x)) / (C + idx),
    bayesian_avg_40 = (C * 0.4 + cumsum(x)) / (C + idx),
    bayesian_avg_50 = (C * 0.5 + cumsum(x)) / (C + idx),
    bayesian_avg_60 = (C * 0.6 + cumsum(x)) / (C + idx),
    bayesian_avg_70 = (C * 0.7 + cumsum(x)) / (C + idx),
    bayesian_avg_80 = (C * 0.8 + cumsum(x)) / (C + idx),
    bayesian_avg_90 = (C * 0.9 + cumsum(x)) / (C + idx),
  ) %>% 
  pivot_longer(
    cols = c(
      cum_mean_plain,
      bayesian_avg_10,
      bayesian_avg_20,
      bayesian_avg_30,
      bayesian_avg_40,
      bayesian_avg_50,
      bayesian_avg_60,
      bayesian_avg_70,
      bayesian_avg_80,
      bayesian_avg_90
    ),
    names_to = "metric",
    values_to = "value"
  ) %>% 
  mutate(is_bayesian_avg = stringr::str_starts(metric, "bayes"))

data_bayes %>% 
  ggplot(
    aes(
      x = idx,
      y = value,
      group = metric,
      color = metric
    )
  ) +
  geom_line(linewidth = 1) +
  scale_y_continuous(limits = c(0, 1)) +
  scale_color_manual(
    values = c(
      "bayesian_avg_10" = "grey80",
      "bayesian_avg_20" = "grey80",
      "bayesian_avg_30" = "grey80",
      "bayesian_avg_40" = "grey80",
      "bayesian_avg_50" = "grey80",
      "bayesian_avg_60" = "grey80",
      "bayesian_avg_70" = "grey80",
      "bayesian_avg_80" = "grey80",
      "bayesian_avg_90" = "grey80",
      "cum_mean" = "black"
    )
  ) +
  geom_hline(yintercept = 0.6, color = "red", linetype = "dashed") +
  geom_text(x = 90, y = 0.57, label = "true upvote rate = 0.6", color = "red") +
  theme_sp() +
  theme(legend.position = "None")

```


## Estimating Global Prior using a Bayesian Hierarchical Model

We can estimate the global priors $C$ and $m$ using a Bayesian Hierarchical model.

Our beliefs about the upvote probability for each post can be modeled using a Beta distribution. Our *prior* beliefs for each post are the same: a Beta distribution with a mean $m$ and sampleSize $C$. 

As we collect data for each post, we can use this not only to update our beliefs about the post, but also to update our beliefs about the global prior. After collecting a lot of data for a lot of posts, we will obviously have a good idea of what the global mean $m$ is. But how do we estimate $C$?

To be able to form and update beliefs about C using a Bayesian approach, we need to have priors beliefs about C. The same for $m$ as a matter of fact. Our priors $m$ and $C$ are our beliefs before we have any data at all.

It's reasonable for the global hyperprior for $m$ to be a uniform distribution: any upvote probability is equally likely before we have any data about any posts.

We also need a hyperprior for $C$. This one is tricky. It's essentially our prior beliefs about how much variation there will be in upvote probabilities for different posts. If it is very high, then no matter what data we observe for a post, the posterior for that post will be close to the global prior $m$. 

It's hard to say much about the hyperprior for $C$ except that it should probably be a positive number and, by experience, between 2 and 10. A gamma distribution is often used for this type of model, for some reason. So we'll choose a weak gamma prior and add 2.


So we have a hierarchical model that looks like this: 

- $m \sim \text{Uniform}(0, 1)$
- $C \sim \text{Gamma}(2, 2)$
- $m_{\text{post}} \sim \text{Beta'}(m, C)$
- $Z \sim \text{Binomial}(n, m_{\text{post}})$

Where $\text{Beta`}$ is a Beta distribution parameterized using mean and sample size instead of $α$ and $β$, using the conversions:

- $\alpha = mean \times sampleSize$
- $\beta = (1 - mean) \times sampleSize$


Using methods such as MCMC, we can estimate the mean of the entire joint probability distribution, giving us an estimated mean weight for each post, and a mean and weight for the global prior.

However, we don't need to rerun the MCMC simulation every time we collect more vote data for a post. Once we have an estimate for $m$ and $C$, we can treat these as fixed. This let's us chop of one level of our hierarchy. Now for each post, we have a simple standard Beta-Bernoulli model. For a Beta-Bernoulli model, the posterior, after observing $upvotes$ upvotes out of $votes$ total votes, is simply:

$$
  Beta(α+upvotes,β+votes-Z)
$$

The mean of this distribution is

$$
  \frac{α + Z}{α + β + n}
$$

Which we can rewrite using the above conversions as:

$$
  \frac{sampleSize \cdot mean + upvotes}{sampleSize + votes}
$$

Using our globalPrior of $mean=m$ and $sampleSize=C$ gives us our formula for the Bayesian Average:

$$
  \frac{sampleSize \cdot mean + upvotes}{sampleSize + votes} \\
  = \frac{C \cdot m + upvotes}{C + votes}
$$



