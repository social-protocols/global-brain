# Vote Rate and Upvote Probability {#vote-rate-upvote-probability}

Users can add **upvotes** and **downvotes** to posts on the platform.
We denote the event of a user adding either an upvote or a downvote to a post simply as a **vote**.
For any given post, we can represent the stream of incoming votes as a Poisson process.

$$
\text{voteRate} \sim \text{Pois}(\lambda_V)
$$

$\lambda_V$ is the rate parameter of the Poisson process.
We call this rate the **vote rate** of the post.
Posts with a high vote rate receive many votes per unit of time, posts with a low vote rate receive few.

We can represent the stream of incoming *upvotes* as a Poisson process as well:

$$
\text{upvoteRate} \sim \text{Pois}(\lambda_U)
$$

We call $\lambda_U$ the **upvote rate**.
The **downvote rate** is defined analogously, but we will mostly ignore it because it can be inferred from the upvote rate and the vote rate and is thus mostly redundant.

<!--- [TODO: graphics exemplifying vote rates] --->


Another important metric is the **upvote ratio**.
Given a tally of votes at a certain point in time, we can calculate the upvote ratio at that time $t$ which is given by $upvotes:downvotes$.
We can also express it as the fraction of upvotes over all votes:

$$
\frac{upvotes}{upvotes + downvotes}
$$

You can think about the upvote fraction as an **average vote** or as the **probability of a vote being an upvote** (we will mostly call this the **upvote probability**).
We can model votes as a Bernoulli distributed random variable with successes given by upvotes and failures given by downvotes.
We can encode upvotes with a value of $1$ and downvotes with a value of $0$.
A sample post's gathered votes at a certain point in time $t$ might look like
this:

$$
(1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0)
$$

The post has gathered a total of 12 votes of which 3 are upvotes and 9 are
downvotes.
The upvote fraction or the average vote for this sample is:

$$
\rho = \frac{\sum_{i=1}^n x_i}{n} = \frac{upvotes}{upvotes + downvotes} = \frac{3}{3 + 9} = 0.25
$$


## Modeling Upvote Probabilities {#modeling-belief-upvote-probability}

We assume that each post has a "true" upvote probability that we can only estimate by collecting votes.
As we model votes as a Bernoulli random variable, we have to model its parameter $p$ (which *is* our upvote probability) as well.
The Beta distribution is a suitable model for proportions or probabilities:

$$
p \sim \beta(upvotes, downvotes)
$$

```{r, include=FALSE}
beta_data <- function(alpha, beta, samples) {
  data.frame(x = seq(0, 1, len = samples)) %>%
    mutate(y = dbeta(x, alpha, beta))
}

```

The Beta distribution has two shape parameters $\alpha$ and $\beta$ which in our case are given by our upvote and downvote counts.
To provide a more intuitive understanding of how this distribution models our upvote probability, here is how our beliefs about the true upvote probability develop for an example post.

Let's say we have a post with a true upvote probability of $0.24$.
We initialize the distribution with a prior of 1 upvote and 1 downvote.
This is equivalent to a uniform distribution:
We assign equal probability to any outcome, i.e., to any upvote probability.

```{r, fig.width=8, fig.height=3}
beta_data(1, 1, 1000) %>%  
  data.frame() %>% 
  ggplot() +
  geom_line(aes(x = x, y = y), color = "black", linewidth = 1) +
  geom_vline(xintercept = 0.24, color = "red", linetype = "dashed") +
  scale_y_continuous(limits = c(0, 4)) +
  labs(
    title = "After 0 votes",
    x = "p",
    y = "Density",
  ) +
  theme_sp()

```

Now, we observe some votes coming in.
We encode upvotes with $1$ and downvotes with $0$.

<!-- (1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0) -->
$$
(\color{limegreen}{1, 0, 0})
$$

```{r, fig.width=8, fig.height=3}
beta_data(2, 3, 1000) %>%  
  data.frame() %>% 
  ggplot() +
  geom_line(aes(x = x, y = y), color = "black", linewidth = 1) +
  geom_vline(xintercept = 0.24, color = "red", linetype = "dashed") +
  scale_y_continuous(limits = c(0, 4)) +
  labs(
    title = "After 3 votes: 1 up, 2 down",
    x = "p",
    y = "Density",
  ) +
  theme_sp()

```

<!-- (1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0) -->
$$
(\color{grey}{1, 0, 0,} \color{limegreen}{0, 1, 0})
$$

```{r, fig.width=8, fig.height=3}
beta_data(3, 5, 1000) %>%  
  data.frame() %>% 
  ggplot() +
  geom_line(aes(x = x, y = y), color = "black", linewidth = 1) +
  geom_vline(xintercept = 0.24, color = "red", linetype = "dashed") +
  scale_y_continuous(limits = c(0, 4)) +
  labs(
    title = "After 6 votes: 2 up, 4 down",
    x = "p",
    y = "Density",
  ) +
  theme_sp()

```

<!-- (1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0) -->
$$
(\color{grey}{1, 0, 0, 0, 1, 0,} \color{limegreen}{0, 0, 0})
$$

```{r, fig.width=8, fig.height=3}
beta_data(3, 8, 1000) %>%  
  data.frame() %>% 
  ggplot() +
  geom_line(aes(x = x, y = y), color = "black", linewidth = 1) +
  geom_vline(xintercept = 0.24, color = "red", linetype = "dashed") +
  scale_y_continuous(limits = c(0, 4)) +
  labs(
    title = "After 9 votes: 2 up, 7 down",
    x = "p",
    y = "Density",
  ) +
  theme_sp()

```

<!-- (1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0) -->
$$
(\color{grey}{1, 0, 0, 0, 1, 0, 0, 0, 0,} \color{limegreen}{1, 0, 0})
$$

```{r, fig.width=8, fig.height=3}
beta_data(4, 10, 1000) %>%  
  data.frame() %>% 
  ggplot() +
  geom_line(aes(x = x, y = y), color = "black", linewidth = 1) +
  geom_vline(xintercept = 0.24, color = "red", linetype = "dashed") +
  scale_y_continuous(limits = c(0, 4)) +
  labs(
    title = "After 12 votes: 3 up, 9 down",
    x = "p",
    y = "Density",
  ) +
  theme_sp()

```

The distribution updates and the probability mass becomes more concentrated which means we become more and more certain about our beliefs about the true upvote probability.
If the post would develop further with a similar trajectory, the following could be the outcome after 500 votes:

```{r, fig.width=8, fig.height=3}
beta_data(120, 380, 1000) %>%  
  data.frame() %>% 
  ggplot() +
  geom_line(aes(x = x, y = y), color = "black", linewidth = 1) +
  geom_vline(xintercept = 0.24, color = "red", linetype = "dashed") +
  labs(
    title = "After 500 votes: 120 up, 380 down",
    x = "p",
    y = "Density",
  ) +
  theme_sp()

```

Our probability mass is now pretty concentrated around what (in this case) we know is the true upvote probability.


<!-- TODO: move to a new chapter (the top note algorithm explanation) -->

<!-- ## Tallies -->

<!-- There are two essential forms of content users can assign votes to: -->
<!-- posts and posts with a note. -->
<!-- For all posts and post/note combinations, we keep a tally of upvotes and downvotes. -->

<!-- ```{r} -->
<!-- knitr::include_graphics("images/tallies.png") -->

<!-- ``` -->


## Estimating the Upvote Probability: Naive Approach

Now that we can express our beliefs about the upvote probability, how do we make a "best guess" at any given point in time?
A naive way of estimating the upvote probability is to take the actual current ratio $upvotes:downvotes$, or rather the fraction, which is equivalent to the **plain sample average vote**:

$$
P_t(upvote) = \frac{\sum_{i=1}^n x_i}{n} = \frac{upvotes}{upvotes + downvotes}
$$

This solution is naive because it ignores an important fact:
In the beginning, we have **no information** about the upvote probability of the post.
Thus, each new arriving vote has an outsized effect on our estimate that just
gets increasingly small over time.
This would result in **erratic estimates** in the beginning which would only
smooth out over time.
Here is how the cumulative mean develops for a random vote history with a true
upvote rate of $0.6$:

```{r, fig.width=8, fig.height=5}
set.seed(5)
n_votes <- 100
data <- data.frame(
  idx = seq(1, n_votes),
  x = rbinom(n_votes, size = 1, 0.6)
) %>% 
  mutate(cum_mean = cummean(x))

data %>% 
  ggplot(aes(x = idx, y = cum_mean)) +
  geom_line(color = "firebrick", linewidth = 1) +
  scale_y_continuous(limits = c(0, 1)) +
  geom_hline(yintercept = 0.6, color = "black", linetype = "dashed") +
  geom_text(x = 90, y = 0.65, label = "true upvote rate: 0.6") +
  labs(
    x = "After N votes",
    y = "Cumulative Mean"
  ) +
  theme_sp()

```

If we were to use this metric to compare posts, getting a high upvote probability
estimate in the early stages of a post would essentially come down to luck.
It might then temporarily fare overly well (or overly poorly) compared to other
posts.
We have to take into account **prior information** to avoid this.


## The Bayesian Average

The Bayesian Average uses a **weighted prior estimate of the average** to avoid the
erratic shifts in the estimate when there is not a lot of data.
It is calculated as...

$$
\frac{\color{blue}{C \cdot m} + \sum_{i=1}^n x_i}{\color{blue}{C} + n}
$$

... where $C$ is a weight constant and $m$ is our prior belief about the average.
If you compare it to the plain average, <span style="color: blue">we simply add $C \cdot m$ to the nominator and $C$ to the denominator</span>.

**But what does this achieve in concrete terms?**

Let's build up to this formula step by step for estimating the
true upvote probability of a post.
First, remember that the sample upvote fraction can be thought of as the "plain" average vote.
Let's say our dataset $X$ consists of $1$s and $0$s, where $1$ denotes an upvote and $0$ denotes a downvote.
Then $\sum_{i=1}^n{x_i}$ is the *number of upvotes* (because downvotes are
encoded as $0$s) and $n$ is $upvotes + downvotes$, the *total number of votes*.
Substituting the values in the Bayesian average formula gives us:

$$
\frac{C \cdot m + \sum_{i=1}^n x_i}{C + n} = \frac{C \cdot m + upvotes}{C + upvotes + downvotes}
$$

**Practically, adding these terms to our formula means that we calculate the
cumulative average as if we had collected $C$ votes with an upvote rate of $m$
before we collected the first vote on our post.**

If our prior belief about the average is $0.68$ and we chose a weighting factor of
$100$, this would mean that we calculate the average as if we had previously
collected $100$ data points which amounted to an upvote fraction of exactly $0.68$.

Plugging in the values makes this apparent:

$$
\frac{100 \cdot 0.68 + upvotes}{100 + upvotes + downvotes} = \frac{68 + upvotes}{100 + upvotes + downvotes}
$$

Graphically, it looks like this (the light grey line is the plain average for
comparison):

```{r, fig.width=8, fig.height=5}
set.seed(12)
n_votes <- 100
votes <- rbinom(n_votes, size = 1, 0.6)
data_plain <- data.frame(
  idx = seq(1, n_votes),
  x = votes,
  is_prior = FALSE
) %>% 
  mutate(cum_mean_plain = cummean(x)) %>% 
  union(
    data.frame(
      idx = seq(-9, 0),
      x = NA,
      is_prior = TRUE,
      cum_mean_plain = NA
    )
  ) %>% 
  arrange(idx) %>% 
  select(-x)

data_bayes <- data.frame(
  idx = seq(1, n_votes),
  x = votes,
  is_prior = FALSE
) %>% 
  union(
    data.frame(
      idx = seq(-9, 0),
      x = 0.68,
      is_prior = TRUE
    )
  ) %>% 
  arrange(idx) %>% 
  mutate(cum_mean_bayes = cummean(x)) %>% 
  select(-x)

data_plain %>% 
  left_join(data_bayes, by = c("idx", "is_prior")) %>% 
  pivot_longer(
    cols = c(cum_mean_plain, cum_mean_bayes),
    names_to = "metric",
    values_to = "value",
    values_drop_na = TRUE
  ) %>% 
  ggplot(aes(x = idx, y = value)) +
  geom_line(aes(alpha = metric), linewidth = 1) +
  scale_y_continuous(limits = c(0, 1)) +
  scale_alpha_manual(
    values = c(
      "cum_mean_bayes" = 1.0,
      "cum_mean_plain" = 0.2
    ),
  ) +
  geom_text(x = 16, y = 0.95, label = "start of data collection") +
  geom_text(x = 90, y = 0.55, label = "true upvote rate", color = "red") +
  geom_text(x = -5, y = 0.72, label = "prior", color = "black") +
  geom_hline(yintercept = 0.6, color = "red", linetype = "dashed") +
  geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
  labs(
    x = "After N votes",
    y = "Cumulative Bayesian Average"
  ) +
  theme_sp() +
  theme(legend.position = "None")

```

The cumulative Bayesian average is much less erratic when little data is available.
However, there is an important question left:
How do we chose a good prior and a good weight?

Here is how the Bayesian average develops for different prior beliefs about the
average.
Bayesian averages over time are indicated by light grey lines, the priors chosen
here are $0.1$ through $0.9$ and the weight is kept constant at $20$.
The plain average is overlayed in darker grey for reference.

```{r, fig.width=8, fig.height=5}
C <- 20

data_plain <- data.frame(
  idx = seq(1, n_votes),
  x = votes
) %>% 
  mutate(cum_mean_plain = cummean(x))
  
data_bayes <-
  data_plain %>%
  mutate(
    bayesian_avg_10 = (C * 0.1 + cumsum(x)) / (C + idx),
    bayesian_avg_20 = (C * 0.2 + cumsum(x)) / (C + idx),
    bayesian_avg_30 = (C * 0.3 + cumsum(x)) / (C + idx),
    bayesian_avg_40 = (C * 0.4 + cumsum(x)) / (C + idx),
    bayesian_avg_50 = (C * 0.5 + cumsum(x)) / (C + idx),
    bayesian_avg_60 = (C * 0.6 + cumsum(x)) / (C + idx),
    bayesian_avg_70 = (C * 0.7 + cumsum(x)) / (C + idx),
    bayesian_avg_80 = (C * 0.8 + cumsum(x)) / (C + idx),
    bayesian_avg_90 = (C * 0.9 + cumsum(x)) / (C + idx),
  ) %>% 
  pivot_longer(
    cols = c(
      cum_mean_plain,
      bayesian_avg_10,
      bayesian_avg_20,
      bayesian_avg_30,
      bayesian_avg_40,
      bayesian_avg_50,
      bayesian_avg_60,
      bayesian_avg_70,
      bayesian_avg_80,
      bayesian_avg_90
    ),
    names_to = "metric",
    values_to = "value"
  ) %>% 
  mutate(is_bayesian_avg = stringr::str_starts(metric, "bayes"))

data_bayes %>% 
  ggplot(
    aes(
      x = idx,
      y = value,
      group = metric,
      color = metric
    )
  ) +
  geom_line(linewidth = 1) +
  scale_y_continuous(limits = c(0, 1)) +
  scale_color_manual(
    values = c(
      "bayesian_avg_10" = "grey80",
      "bayesian_avg_20" = "grey80",
      "bayesian_avg_30" = "grey80",
      "bayesian_avg_40" = "grey80",
      "bayesian_avg_50" = "grey80",
      "bayesian_avg_60" = "grey80",
      "bayesian_avg_70" = "grey80",
      "bayesian_avg_80" = "grey80",
      "bayesian_avg_90" = "grey80",
      "cum_mean" = "black"
    )
  ) +
  geom_hline(yintercept = 0.6, color = "red", linetype = "dashed") +
  geom_text(x = 90, y = 0.57, label = "true upvote rate = 0.6", color = "red") +
  theme_sp() +
  theme(legend.position = "None")

```

And here is that same plot with the same priors, but with a weight of $100$.

```{r, fig.width=8, fig.height=5}
C <- 100

data_plain <- data.frame(
  idx = seq(1, n_votes),
  x = votes
) %>% 
  mutate(cum_mean_plain = cummean(x))
  
data_bayes <-
  data_plain %>%
  mutate(
    bayesian_avg_10 = (C * 0.1 + cumsum(x)) / (C + idx),
    bayesian_avg_20 = (C * 0.2 + cumsum(x)) / (C + idx),
    bayesian_avg_30 = (C * 0.3 + cumsum(x)) / (C + idx),
    bayesian_avg_40 = (C * 0.4 + cumsum(x)) / (C + idx),
    bayesian_avg_50 = (C * 0.5 + cumsum(x)) / (C + idx),
    bayesian_avg_60 = (C * 0.6 + cumsum(x)) / (C + idx),
    bayesian_avg_70 = (C * 0.7 + cumsum(x)) / (C + idx),
    bayesian_avg_80 = (C * 0.8 + cumsum(x)) / (C + idx),
    bayesian_avg_90 = (C * 0.9 + cumsum(x)) / (C + idx),
  ) %>% 
  pivot_longer(
    cols = c(
      cum_mean_plain,
      bayesian_avg_10,
      bayesian_avg_20,
      bayesian_avg_30,
      bayesian_avg_40,
      bayesian_avg_50,
      bayesian_avg_60,
      bayesian_avg_70,
      bayesian_avg_80,
      bayesian_avg_90
    ),
    names_to = "metric",
    values_to = "value"
  ) %>% 
  mutate(is_bayesian_avg = stringr::str_starts(metric, "bayes"))

data_bayes %>% 
  ggplot(
    aes(
      x = idx,
      y = value,
      group = metric,
      color = metric
    )
  ) +
  geom_line(linewidth = 1) +
  scale_y_continuous(limits = c(0, 1)) +
  scale_color_manual(
    values = c(
      "bayesian_avg_10" = "grey80",
      "bayesian_avg_20" = "grey80",
      "bayesian_avg_30" = "grey80",
      "bayesian_avg_40" = "grey80",
      "bayesian_avg_50" = "grey80",
      "bayesian_avg_60" = "grey80",
      "bayesian_avg_70" = "grey80",
      "bayesian_avg_80" = "grey80",
      "bayesian_avg_90" = "grey80",
      "cum_mean" = "black"
    )
  ) +
  geom_hline(yintercept = 0.6, color = "red", linetype = "dashed") +
  geom_text(x = 90, y = 0.57, label = "true upvote rate = 0.6", color = "red") +
  theme_sp() +
  theme(legend.position = "None")

```


## Estimating Global Prior using Bayesian Hierarchical Model

We can estimate the global priors $C$ and $m$ using a Bayesian Hierarchical model.

Our beliefs about the upvote probability for each post can be modeled using a Beta distribution. Our *prior* beliefs for each post are the same: a Beta distribution with a mean $m$ and sampleSize $C$. 

As we collect data for each post, we can use this not only to update our beliefs about the post, but also to update our beliefs about the global prior. After collecting a lot of data for a lot of posts, we will obviously have a good idea of what the global mean $m$ is. But how do we estimate $C$?

To be able to form and update beliefs about C using a Bayesian approach, we need to have priors beliefs about C. The same for $m$ as a matter of fact. Our priors $m$ and $C$ are our beliefs before we have any data at all.

It's reasonable for the global hyperprior for $m$ to be a uniform distribution: any upvote probability is equally likely before we have any data bout any posts.

We also need a hyperprior for $C$. This one is tricky. It's essentially our prior beliefs about how much variation there will be in upvote probabilities for different posts. IF it is very high, then no matter what data we observe for a post, the posterior for that post will be close to the global prior $m$. 

It's hard to say much about the hyperprior for $C$ except that it should probably be a positive number and, by experience, between 2 and 10. A gamma distribution is often used for this type of model, for some reason. So we'll choose a weak gamma prior and add 2.


So we have a hierarchical model that looks like this: 

- $m \sim \text{Uniform}(0, 1)$
- $C \sim \text{Gamma}(2, 2)$
- $m_{\text{post}} \sim \text{Beta'}(m, C)$
- $Z \sim \text{Binomial}(n, m_{\text{post}})$

Where $\text{Beta`}$ is a Beta distribution parameterized using mean and sample size instead of $α$ and $β$, using the conversions:

- $\alpha = mean \times sampleSize$
- $\beta = (1 - mean) \times sampleSize$


Using methods such as MCMC, we can estimate the mean of the entire join probability distribution, giving us an estimated mean weight for each post, and a mean and weight for the global prior.

However, we don't need to rerun the MCMC simulation every time we collect more vote data for a post. Once we have an estimate for $m$ and $C$, we can treat these as fixed. This let's us chop of one level of our hierarchy. Now for each post, we have a simple Beta-Bernoulli model. For a Beta-Bernoulli model, the posterior, after observing $Z$ upvotes out of $n$ total votes, is:

$$
  Beta(α+Z,β+n-Z)
$$

The mean of this distribution is

$$
  \frac{α + Z}{α + β + n}
$$

Which we can rewrite as

$$
  \frac{sampleSize \cdot mean + Z}{sampleSize + n}
$$

Uaing our globalPrior of $mean=m$ and $sampleSize=C$ gives us our formula for the Bayesian Average:

$$
  \frac{sampleSize \cdot mean + Z}{sampleSize + n}
$$



